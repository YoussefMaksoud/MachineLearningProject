{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INST</th>\n",
       "      <th>RPLACE</th>\n",
       "      <th>RCOUNTY</th>\n",
       "      <th>PLURAL</th>\n",
       "      <th>BDATE</th>\n",
       "      <th>BMONTH</th>\n",
       "      <th>BDAY</th>\n",
       "      <th>BYEAR</th>\n",
       "      <th>SEX</th>\n",
       "      <th>RACE</th>\n",
       "      <th>...</th>\n",
       "      <th>MOTHERTR</th>\n",
       "      <th>IANEMIA</th>\n",
       "      <th>BINJURY</th>\n",
       "      <th>FAS</th>\n",
       "      <th>HYALINE</th>\n",
       "      <th>ASPIRATE</th>\n",
       "      <th>VENTLESS</th>\n",
       "      <th>VENTMORE</th>\n",
       "      <th>ISEIZURE</th>\n",
       "      <th>OTHINF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6800</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>2008-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2008</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2008-01-02</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>190</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2008-01-02</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4100</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>2008-01-03</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2008</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2008-01-03</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2008</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133417</th>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>2008-12-19</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133418</th>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>2008-12-22</td>\n",
       "      <td>12</td>\n",
       "      <td>22</td>\n",
       "      <td>2008</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133419</th>\n",
       "      <td>1</td>\n",
       "      <td>2600</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>2008-12-26</td>\n",
       "      <td>12</td>\n",
       "      <td>26</td>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133420</th>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>2008-12-30</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>2008</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133421</th>\n",
       "      <td>1</td>\n",
       "      <td>8100</td>\n",
       "      <td>81</td>\n",
       "      <td>1</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>133422 rows Ã— 125 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        INST  RPLACE  RCOUNTY  PLURAL       BDATE  BMONTH  BDAY  BYEAR  SEX  \\\n",
       "0          1    6800       68       1  2008-01-01       1     1   2008    2   \n",
       "1          1     160        1       1  2008-01-02       1     2   2008    2   \n",
       "2          1     190        1       1  2008-01-02       1     2   2008    1   \n",
       "3          1    4100       41       1  2008-01-03       1     3   2008    2   \n",
       "4          1     160        1       1  2008-01-03       1     3   2008    2   \n",
       "...      ...     ...      ...     ...         ...     ...   ...    ...  ...   \n",
       "133417     1    2000       20       1  2008-12-19      12    19   2008    1   \n",
       "133418     1    2000       20       1  2008-12-22      12    22   2008    2   \n",
       "133419     1    2600       26       1  2008-12-26      12    26   2008    1   \n",
       "133420     1    2000       20       1  2008-12-30      12    30   2008    2   \n",
       "133421     1    8100       81       1  2008-12-31      12    31   2008    1   \n",
       "\n",
       "        RACE  ...  MOTHERTR  IANEMIA  BINJURY  FAS  HYALINE  ASPIRATE  \\\n",
       "0          1  ...         2        0        0    0        0         0   \n",
       "1          2  ...         2        0        0    0        0         0   \n",
       "2          1  ...         2        0        0    0        0         0   \n",
       "3          1  ...         2        0        0    0        0         0   \n",
       "4          1  ...         2        0        0    0        0         0   \n",
       "...      ...  ...       ...      ...      ...  ...      ...       ...   \n",
       "133417     1  ...         2        9        9    9        9         9   \n",
       "133418     1  ...         2        9        9    9        9         9   \n",
       "133419     1  ...         2        9        9    9        9         9   \n",
       "133420     1  ...         2        9        9    9        9         9   \n",
       "133421     0  ...         2        9        9    9        9         9   \n",
       "\n",
       "        VENTLESS  VENTMORE  ISEIZURE  OTHINF  \n",
       "0              0         0         0       0  \n",
       "1              0         0         0       0  \n",
       "2              0         0         0       0  \n",
       "3              0         0         0       0  \n",
       "4              0         0         0       0  \n",
       "...          ...       ...       ...     ...  \n",
       "133417         9         9         9       9  \n",
       "133418         9         9         9       9  \n",
       "133419         9         9         9       9  \n",
       "133420         9         9         9       9  \n",
       "133421         9         9         9       9  \n",
       "\n",
       "[133422 rows x 125 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "data = pd.read_csv(\"../data/2008_births.csv\")\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.1875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.3750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.4375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133417</th>\n",
       "      <td>6.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133418</th>\n",
       "      <td>9.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133419</th>\n",
       "      <td>8.4375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133420</th>\n",
       "      <td>5.8125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133421</th>\n",
       "      <td>7.1875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>133422 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        total_weight\n",
       "0             4.0625\n",
       "1             8.1875\n",
       "2             9.0000\n",
       "3             7.3750\n",
       "4             9.4375\n",
       "...              ...\n",
       "133417        6.5000\n",
       "133418        9.1250\n",
       "133419        8.4375\n",
       "133420        5.8125\n",
       "133421        7.1875\n",
       "\n",
       "[133422 rows x 1 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#birthweight is what we want to predict - change this to single target \n",
    "birth_weight = data[['BPOUND', 'BOUNCE']] \n",
    "birth_weight = birth_weight.assign(total_weight = lambda x: birth_weight['BPOUND'] + (birth_weight['BOUNCE']/16))\n",
    "birth_weight = birth_weight.drop(['BPOUND', 'BOUNCE'], axis = 1) \n",
    "birth_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA might be a good technique to select predictors \n",
    "\n",
    "#note that PCA performs best when data is normalized (range b/w 0 and 1)\n",
    "\n",
    "#It is possible to use categorical and continuous predictors \n",
    "#for a regression problem. My understanding is you need to make \n",
    "#dummy variables for the binary predictors. \n",
    "\n",
    "#Variables that we will need to deal with: \n",
    "# BDATE, HISPMOM, HISPDAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Attempting PCA on data\n",
    "#for now I drop the BDATE, HISPMOM AND HISPDAD\n",
    "data_drop = data.drop([\"BDATE\", \"HISPMOM\", \"HISPDAD\", \"BOUNCE\", \"BPOUND\"], axis = 1) #axis = 1 means to drop column not row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get a list of columns in pandas object \n",
    "names_of_data = data_drop.columns.tolist()\n",
    "\n",
    "#shuffle = false prevents data split being different everytime\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_drop, birth_weight, test_size = 0.2, shuffle = False)\n",
    "\n",
    "#split test into validate and test, again making sure the data is always the same for consistency\n",
    "##X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, shuffle = False)\n",
    "\n",
    "#Normalizing the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "#running the actual PCA\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA()\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "\n",
    "#relief f algorithm - sorting features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n",
      "[3.89856404e-02 3.41089470e-02 3.05310536e-02 2.86690661e-02\n",
      " 2.39828710e-02 2.07124228e-02 1.81565355e-02 1.70798239e-02\n",
      " 1.68763289e-02 1.59961073e-02 1.56220702e-02 1.35585642e-02\n",
      " 1.30251204e-02 1.13087563e-02 1.10457470e-02 1.09427186e-02\n",
      " 1.06522571e-02 1.03091115e-02 1.02034145e-02 1.01603763e-02\n",
      " 9.98586972e-03 9.86404012e-03 9.78778404e-03 9.61165628e-03\n",
      " 9.46902421e-03 9.40630729e-03 9.25092446e-03 9.20797437e-03\n",
      " 9.16882901e-03 9.11728971e-03 9.08471022e-03 9.05880935e-03\n",
      " 8.91090184e-03 8.85632587e-03 8.83902308e-03 8.82366452e-03\n",
      " 8.73228213e-03 8.70972804e-03 8.64475483e-03 8.63888132e-03\n",
      " 8.60300393e-03 8.57402898e-03 8.54542908e-03 8.51710741e-03\n",
      " 8.50298288e-03 8.46111398e-03 8.42122923e-03 8.39505222e-03\n",
      " 8.37548109e-03 8.34046815e-03 8.29732609e-03 8.28947627e-03\n",
      " 8.24895028e-03 8.22904830e-03 8.20238682e-03 8.12690154e-03\n",
      " 8.11341630e-03 8.08291392e-03 8.07851589e-03 8.03763212e-03\n",
      " 8.01473052e-03 7.96613523e-03 7.90999598e-03 7.89944166e-03\n",
      " 7.83600377e-03 7.82191448e-03 7.78512254e-03 7.75691445e-03\n",
      " 7.69956508e-03 7.66449230e-03 7.60968558e-03 7.58920895e-03\n",
      " 7.51965207e-03 7.50072699e-03 7.41546041e-03 7.36057792e-03\n",
      " 7.17224177e-03 7.11636014e-03 7.01568819e-03 6.99311496e-03\n",
      " 6.88970752e-03 6.80287045e-03 6.71667348e-03 6.59331242e-03\n",
      " 6.56011619e-03 6.39097514e-03 6.21038587e-03 6.13263995e-03\n",
      " 6.02101475e-03 5.88755078e-03 5.62716616e-03 5.49427350e-03\n",
      " 5.42691648e-03 5.30849077e-03 5.16759622e-03 4.77164460e-03\n",
      " 4.64430993e-03 4.52817477e-03 4.35785968e-03 4.10170975e-03\n",
      " 3.95902522e-03 3.70091254e-03 3.10259706e-03 2.89941030e-03\n",
      " 2.48400831e-03 1.79876640e-03 1.72329185e-03 9.56485073e-04\n",
      " 9.01290670e-04 6.15880756e-04 5.54770674e-04 2.94096489e-04\n",
      " 1.90827613e-04 3.83559595e-08 7.68856188e-33 7.62231993e-33\n",
      " 2.16597016e-33 1.43573650e-33 2.23811207e-34 1.98989560e-34]\n"
     ]
    }
   ],
   "source": [
    "explained_variance = pca.explained_variance_ratio_\n",
    "print(len(explained_variance))\n",
    "print(explained_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Explained variance prints the variance each principal component contributes.\n",
    "#As we can see, the last 5 contribute very little (maybe we can get rid of?)\n",
    "\n",
    "#We also want to check for linearity between the input predictors and the output \n",
    "#If there is high colinearity, then we want to use ridge regression - A variant of lin regression that has regulatization\n",
    "\n",
    "#Correlation indicates strength and direction of a linear relationship. let's use this on the predictors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor as reg\n",
    "nn = reg(activation = 'relu', solver = 'adam', learning_rate_init = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>106737</th>\n",
       "      <td>7.8125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106738</th>\n",
       "      <td>7.6875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106739</th>\n",
       "      <td>5.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106740</th>\n",
       "      <td>8.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106741</th>\n",
       "      <td>6.3750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133417</th>\n",
       "      <td>6.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133418</th>\n",
       "      <td>9.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133419</th>\n",
       "      <td>8.4375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133420</th>\n",
       "      <td>5.8125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133421</th>\n",
       "      <td>7.1875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26685 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        total_weight\n",
       "106737        7.8125\n",
       "106738        7.6875\n",
       "106739        5.1250\n",
       "106740        8.0000\n",
       "106741        6.3750\n",
       "...              ...\n",
       "133417        6.5000\n",
       "133418        9.1250\n",
       "133419        8.4375\n",
       "133420        5.8125\n",
       "133421        7.1875\n",
       "\n",
       "[26685 rows x 1 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[[\"total_weight\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPRegressor(learning_rate_init=0.01)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "nn.fit(X_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8.2060987 , 7.37414802, 5.11214767, ..., 5.43307517, 5.43307517,\n",
       "       5.43307517])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = nn.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3342447580055667"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
